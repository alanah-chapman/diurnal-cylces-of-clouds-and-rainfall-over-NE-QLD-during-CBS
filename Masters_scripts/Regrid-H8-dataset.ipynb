{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d2ebef7-a638-4846-9cf2-f413f0e8e806",
   "metadata": {},
   "source": [
    "# This notebook contains:\n",
    "* Functions to regrid the channel 13 brightness temperature for the study domain and save the regridded dataset as a netcdf4 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cddb1cd-3aac-49fa-b044-096937b2d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import numpy as np\n",
    "from numpy import s_\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import metpy\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "from scipy.interpolate import griddata\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6edb977",
   "metadata": {},
   "source": [
    "# Functions to open, regrid, and save satellite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dd5854e-d3a3-40b3-86fc-a5aa7e3294d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in_directory(directory: str) -> list[str]:\n",
    "    \"\"\"Function to return the full list of file paths to the Himawari dataset (strings)\n",
    "\n",
    "    Args:\n",
    "        directory (str): String where netcdf files are stored\n",
    "\n",
    "    Returns:\n",
    "        list[str]: Returns a list of file paths (str)\n",
    "    \"\"\"\n",
    "    file_paths = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".nc\"):  # Checks for the \".nc\" file extension\n",
    "                file_paths.append(os.path.join(root, file))\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def regrid_H8_dataset(file_paths: list[str],attrs_note: str) -> xr.Dataset:\n",
    "    \"\"\"Function to regrid the satellite dataset, and storing as a new xr.Dataset \n",
    "\n",
    "    Args:\n",
    "        file_paths (list[str]): List of file paths as strings\n",
    "        attrs_note (str): Note to add to produced dataset attributes about time period and resolution of regridded dataset e.g. JFM ch13BT for study domain with natural satellite res (2km). File created with xarray and xesmf.\n",
    "\n",
    "    Returns:\n",
    "        xr.Dataset: Regridded channel 13 BT output (xr.Dataset) with time, lat and lon coordinates  \n",
    "    \"\"\"\n",
    "    output = []\n",
    "    for file in file_paths:\n",
    "        # select elements and lines (x,y) for the study domain of interest (reduces computational time)\n",
    "        with xr.open_dataset(file, engine=\"h5netcdf\").sel(elements=slice(2500,3500),lines=slice(1800,2320)) as ds:\n",
    "            # xesmf can only recognise 'lat' and 'lon', so rename pixel_latitude and pixel_longitude variables\n",
    "            ds = ds.rename({\n",
    "            \"pixel_latitude\": \"lat\",\n",
    "            \"pixel_longitude\": \"lon\"\n",
    "            })\n",
    "            # chunk native coordinates of dataset before regridding\n",
    "            ds_chunked = ds.chunk({'elements': 'auto', 'lines': 'auto'}) \n",
    "            # create a latlong grid using xesmf regridder\n",
    "            out_grid = xe.util.grid_2d(lat0_b=-22, lat1_b=-14, lon0_b=143, lon1_b=152, d_lat=0.018, d_lon=0.018)\n",
    "            lon = np.arange(143, 152.018, 0.018)\n",
    "            lon = xr.DataArray(lon, dims=('lon',), coords={'lon': lon}, attrs={'name': 'Longitude', 'units': 'degree_east'})\n",
    "            lat = np.arange(-22, -13.982, 0.018)\n",
    "            lat = xr.DataArray(lat, dims=('lat',), coords={'lat': lat}, attrs={'name': 'Latitude', 'units': 'degree_north'})\n",
    "            out_grid=xr.Dataset({'lat': lat, 'lon': lon})\n",
    "               # mask = np.ones_like(ds.lat)\n",
    "               # mask = xr.DataArray(mask, dims=('lines', 'elements'), coords={'lines': ds.lines, 'elements': ds.elements})\n",
    "            # regrid\n",
    "               # ds = ds_chunked.where(mask==1, drop=True)    \n",
    "            regridder = xe.Regridder(ds_chunked, out_grid, 'bilinear')\n",
    "            dr = ds_chunked[\"himawari_8_ahi_channel_13_brightness_temperature\"]\n",
    "            dr_out = regridder(dr)\n",
    "            # create xr dataset with time coordinates\n",
    "            dr_out.lon.attrs['units'] = 'degree_east'\n",
    "            dr_out.lat.attrs['units'] = 'degree_south'\n",
    "            fn = os.path.basename(file)                                     # extract filepath name\n",
    "            print(fn)\n",
    "            date_string = fn[20:30]                                         # extract out datetime info from filename\n",
    "            date_format = \"%Y%j.%H\"                                         # give file format\n",
    "            date_time_obj = datetime.strptime(date_string, date_format)     # convert him8 filename date info to a datetime object\n",
    "            time = [date_time_obj ]                                         # create array with time values\n",
    "            time_index = pd.to_datetime(time)\n",
    "            ds0 = xr.Dataset({'ch13BT':dr_out})\n",
    "            # add time to dims\n",
    "            ds_time = ds0.expand_dims(time=[time_index[0]])\n",
    "            # create xarray dataset\n",
    "            ds_him8 = xr.Dataset({'ch13BT':ds_time.ch13BT}, \n",
    "                            attrs={'note':attrs_note})\n",
    "            output.append(ds_him8)\n",
    "    return output\n",
    "\n",
    "\n",
    "def save_to_netcdf(regridded_ds: xr.Dataset,file_name: str) -> None:\n",
    "    \"\"\"Function to save the regridded satellite (ch13BT) dataset to a netcdf4 file\n",
    "\n",
    "    Args:\n",
    "        regridded_ds (xr.Dataset): Regridded dataset produced by the function named: regrid_H8_dataset\n",
    "        file_name (str): Name saved file\n",
    "    \"\"\"\n",
    "    # concatenate files by time\n",
    "    concat_regridded_ds = xr.concat(regridded_ds,'time')\n",
    "    concat_regridded_ds.to_netcdf(file_name+'.nc', format='NETCDF4', \n",
    "             encoding={'ch13BT':{\n",
    "                       'shuffle':True,              # increases effectiveness of compression when True\n",
    "                       'chunksizes':[1,446,502],    # length of [time, lat, lon] variables\n",
    "                       'zlib':True,                 # compression type, required to be True to specify compression levels below\n",
    "                       'complevel':5                # specifies compression levels, range(0,9) with 0: no compression, 9: fully compressed\n",
    "            }})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d16dba",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc2e4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regrid JFM 2016-2020 for climatology work\n",
    "directory_clim = \"/g/data/gy85/Himawari8_AusGeo1-0-3/L1/\" \n",
    "file_paths_clim = list_files_in_directory(directory_clim)\n",
    "file_paths_clim.sort()\n",
    "\n",
    "# Get filepaths for Jan-Mar separating by year (the Coral Bleaching Season)\n",
    "year_filenames = {}  \n",
    "for file in file_paths_clim:\n",
    "    fn = os.path.basename(file)\n",
    "    ND_day_str = fn[24:27]        # day of year in filepath string\n",
    "    ND_days = int(ND_day_str)     # convert day string to integer\n",
    "    if ND_days >= 100:            # removing nov-dec files\n",
    "        pass\n",
    "    else:\n",
    "        year = fn[20:24]          # Extract the year information from the file name\n",
    "        # Check if the year is already in the dictionary, if not, create a new list\n",
    "        if year not in year_filenames:\n",
    "            year_filenames[year] = []\n",
    "        # Append the file name to the list associated with that hour\n",
    "        year_filenames[year].append(file)\n",
    "\n",
    "# Convert the dictionary values (lists of file names) to lists\n",
    "yearly_file_lists = list(year_filenames.values())\n",
    "\n",
    "# Regrid each year of JFM hourly files - this will take some time (~1.5hours for each year)\n",
    "# ch13bt_2016 = regrid_H8_dataset(yearly_file_lists[0],'2016 JFM regridded ch13BT for study domain, natural satellite res (2km). Dataset created with xarray and xesmf.')\n",
    "# ch13bt_2017 = regrid_H8_dataset(yearly_file_lists[1],'2017 JFM regridded ch13BT for study domain, natural satellite res (2km). Dataset created with xarray and xesmf.')\n",
    "# ch13bt_2018 = regrid_H8_dataset(yearly_file_lists[2],'2018 JFM regridded ch13BT for study domain, natural satellite res (2km). Dataset created with xarray and xesmf.')\n",
    "# ch13bt_2019 = regrid_H8_dataset(yearly_file_lists[3],'2019 JFM regridded ch13BT for study domain, natural satellite res (2km). Dataset created with xarray and xesmf.')\n",
    "# ch13bt_2020 = regrid_H8_dataset(yearly_file_lists[4],'2020 JFM regridded ch13BT for study domain, natural satellite res (2km). Dataset created with xarray and xesmf.')\n",
    "\n",
    "# Save as netcdf4 file\n",
    "# save_to_netcdf(ch13bt_2020,'2020_ch13BT_regridded_2kmres') #..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46ebccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regrid DJF for case study work\n",
    "directory_case_study = \"/g/data/v46/lb5963/HIMAWARI/08_V46_SUMM_2021-22/L1/\" # may no longer be stored here?\n",
    "file_paths_case_study = list_files_in_directory(directory_case_study)\n",
    "file_paths_case_study.sort()\n",
    "\n",
    "# get filepaths for DJF for 2021-2022\n",
    "filepaths = file_paths_case_study[720:2804] \n",
    "\n",
    "# Regrid\n",
    "# ch13bt_2022 = regrid_H8_dataset(filepaths,'2021-2022 DJF regridded ch13BT for study domain, natural satellite res (2km). Dataset created with xarray and xesmf.')\n",
    "# save_to_netcdf(ch13bt_2020,'2022_ch13BT_regridded')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
